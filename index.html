<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0030)https://pengsongyou.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Weifeng Lin</title>
  
  <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE">	
  <meta name="viewport" content="‚Äúwidth=800‚Äù">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">

  <style type="text/css">
    @import url(http://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300,100italic,100);
      /* Color scheme stolen from Sergey Karayev */
      a {
      /*color: #b60a1c;*/
      color: #1772d0;
      /*color: #bd0a36;*/
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th,tr,p,a {
      font-family: 'Roboto', sans-serif;
      font-size: 15px;
      font-weight: 300;
      }
      strong {
      font-family: 'Roboto', sans-serif;
      /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
      /*font-family: 'Avenir Next';*/
      font-size: 15px;
      font-weight: 400;
      }
      heading {
      /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
      font-family: 'Roboto', sans-serif;
      /*font-family: 'Avenir Next';*/
      /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
      font-size: 24px;
      font-weight: 400;
      }
      papertitle {
      /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
      font-family: 'Roboto', sans-serif;
      /*font-family: 'Avenir Next';*/
      /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
      font-size: 15px;
      font-weight:500;
      }
      name {
      /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
      font-family: 'Roboto', sans-serif;
      /*font-family: 'Avenir Next';*/
      font-weight: 400;
      font-size: 32px;
      }
      .one
      {
      width: 160px;
      height: 140px;
      position: relative;
      }
      .two
      {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
      }
      .fade {
       transition: opacity .2s ease-in-out;
       -moz-transition: opacity .2s ease-in-out;
       -webkit-transition: opacity .2s ease-in-out;
      }
      span.highlight {
          background-color: #ffffd0;
      }
    </style>
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <!--<tr onmouseout="headshot_stop()" onmouseover="headshot_start()">-->
      <tbody><tr>
        <td width="67%" valign="middle">
          <p align="center">
            <name>Weifeng Lin (ÊûóÁÇú‰∏∞)</name>
            <!--<br>
            ruthfong at robots dot ox dot ac dot uk-->
          </p>

          <p>
            I am a second year Master student at <a href="https://www.scut.edu.cn/en//">South China University of Technology</a>, advised by <a href="http://www.dlvc-lab.net/lianwen/">Prof. Lianwen Jin</a>.
            I received my Bachelor degree also from <a href="https://www.scut.edu.cn/en//">South China University of Technology</a> in 2021, where I spent a wonderful four years.
          </p>
          <p>
            My research interests include Computer Vision (CV), Vision-Language models, Generative model and Robotics. Typically, I am now working on Vision Transformer.
            I am also dedicated to open source endeavors, which I believe is the fundamental element for the sustainable
            development of the AI community.
          </p>
              
          <p align="center">
            <a href="mountchicken@outlook.com">Email</a> &nbsp/&nbsp
            <a href="https://scholar.google.com/citations?user=fzIWn40AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
            <a href="https://github.com/Mountchicken">Github</a>
          </p>
          </td>

          <td width="33%">
            <a href="images/avater.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avater.jpg" class="hoverZoomLink"></a>
          </td>
        </tr>
        </tbody></table>
  
  <!-- Researchs -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Research</heading>
          <p>
            I am currently working on OCR, typically scene text recognition.
          </p>
        </td>
      </tr>
    </tbody>
  </table>
	
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/union14m.png' width="150">
          </div>
        </td>
        <td valign="top" width="75%">
          <a
            href="https://arxiv.org/pdf/2307.08723.pdf">
            <papertitle>Revisiting Scene Text Recognition: A Data Perspective</papertitle>
          </a>
          <br>
          <strong>Qing Jiang</strong>,
          <a>Jiapeng Wang</a>,
          <a>Dezhi Peng</a>,
          <a>Chongyu Liu</a>,
          <a>Lianwen Jin</a>,
          <br>
          <em>ICCV</em>, 2023
          <br>
          <a
            href="https://arxiv.org/pdf/2307.08723.pdf">[paper] </a>
          <a href="https://github.com/Mountchicken/Union14M">[Code] </a>
          <a href="https://huggingface.co/spaces/Mountchicken/MAERec-Gradio">[Demo]</a>
          <br>
          <p>we revisit scene text recognition from a data perspective and argue that the problem of STR is far from being resolved.
          To explore the challenges that STR models still face, we consolidate a large-scale
          STR dataset for analysis and identified seven open challenges. Furthermore, we propose a challenge-driven benchmark to
          facilitate the future development of STR. Additionally, we reveal that the utilization of massive unlabeled data
          through self-supervised pre-training can remarkably enhance the performance of the STR model in real-world scenarios,
          suggesting a practical solution for STR from a data perspective.</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
	    <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/nsr.png' width="150">
          </div>
        </td>
        <td valign="top" width="75%">
					<a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=fzIWn40AAAAJ&citation_for_view=fzIWn40AAAAJ:zYLM7Y9cAGgC">
            <papertitle>A robust and efficient algorithm for Chinese historical document
            analysis and recognition</papertitle>
          </a>
          <br>
            <a>Chongyu Liu</a>,
            <a>Chen Jian</a>,
            <a>Jiarong Huang</a>,
            <a>Wentao Yang</a>,
            <a>Yongxin Shi</a>,
            <strong>Qing Jiang</strong>,
            <a>Lianwen Jin</a>
          <br>
          <em>National Science Review</em>, 2023  
            <br>
							<a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=fzIWn40AAAAJ&citation_for_view=fzIWn40AAAAJ:zYLM7Y9cAGgC">paper</a> 
              <p>A novel and efficient algorithm for Chinese historical document understanding, incorporating three key components: a
              multi-oriented text detector, a dual-path learning-based text recognizer, and a heuristic-based reading order predictor.</p>
        </td>
      </tr>
    </tbody>
  </table>

  <!-- Open source projects -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Open Source</heading>
          <p>
            I am devoted to Open Source projects.
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/mmocr-logo.png' width="160">
          </div>
        </td>
        <td valign="top" width="75%">
          <a href="https://github.com/open-mmlab/mmocr">
            <papertitle>MMOCR</papertitle>
          </a>
          <br>
          <a>MMOCR contributors</a>
          <br>
          <em>Github Repo, 3.5K stars</em>
          <br>
          <a
            href="https://github.com/open-mmlab/mmocr">Github</a>
          <p>OpenMMLab Text Detection, Recognition and Understanding Toolbox.</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/strr.jpeg' width="160">
          </div>
        </td>
        <td valign="top" width="75%">
          <a href="https://github.com/HCIILAB/Scene-Text-Recognition-Recommendations">
            <papertitle>Scene Text Recognition Recommendations</papertitle>
          </a>
          <br>
          <a>Qing Jiang</a>
          <br>
          <em>Github Repo, 231 stars</em>
          <br>
          <a href="https://github.com/HCIILAB/Scene-Text-Recognition-Recommendations">Github</a>
          <p>Long-time maintaining project for recording latest papers, datasets, algorithms, and SOTAs for scene text recognition</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/ocrsam.png' width="160">
          </div>
        </td>
        <td valign="top" width="75%">
          <a href="https://github.com/yeungchenwa/OCR-SAM">
            <papertitle>OCR-SAM</papertitle>
          </a>
          <br>
          <a>Qing Jiang</a>
          <a>Zhenghua Yang</a>
          <br>
          <em>Github Repo, 244 stars</em>
          <br>
          <a href="https://github.com/yeungchenwa/OCR-SAM">Github</a>
          <p>About
          Combining MMOCR with Segment Anything & Stable Diffusion. Automatically detect, recognize and segment text instances,
          with serval downstream tasks, e.g., Text Removal and Text Inpainting</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/edl.png' width="160">
          </div>
        </td>
        <td valign="top" width="75%">
          <a href="https://github.com/Mountchicken/Efficient-Deep-Learning">
            <papertitle>Efficient Deep Learning</papertitle>
          </a>
          <br>
          <a>Qing Jiang</a>
          <br>
          <em>Github Repo, 118 stars</em>
          <br>
          <a href="https://github.com/Mountchicken/Efficient-Deep-Learning">Github</a>
          <p>A bag of tricks to speed up your deep learning process, including Efficient Coding, Efficient Data Processing, Efficient GPUtilization, Efficient Tools, Efficient Training</p>
        </td>
      </tr>
    </tbody>
  </table>
  
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/trcdd.png' width="160">
          </div>
        </td>
        <td valign="top" width="75%">
          <a href="https://github.com/Mountchicken/Text-Recognition-on-Cross-Domain-Datasets">
            <papertitle>Text Recognition on Cross Domain Datasets</papertitle>
          </a>
          <br>
          <a>Qing Jiang</a>
          <br>
          <em>Github Repo, 52 stars</em>
          <br>
          <a href="https://github.com/Mountchicken/Text-Recognition-on-Cross-Domain-Datasetsocr">Github</a>
          <p>Improved Text recognition algorithms on different text domains like scene text, handwritten, document, Chinese/English
          </p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/lora.png' width="160">
          </div>
        </td>
        <td valign="top" width="75%">
          <a href="https://github.com/Mountchicken/Structured_Dreambooth_LoRA">
            <papertitle>Structured Dreambooth LoRA</papertitle>
          </a>
          <br>
          <a>Qing Jiang</a>
          <br>
          <em>Github Repo, 8 stars</em>
          <br>
          <a href="https://github.com/Mountchicken/Structured_Dreambooth_LoRA">Github</a>
          <p>Dreambooth (LoRA) with well-organized code structure. Naive adaptation from Diffusers.
          </p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/pyqt.jpeg' width="160">
          </div>
        </td>
        <td valign="top" width="75%">
          <a href="https://github.com/Mountchicken/CTPN_CRNN_ChineseOCR_PyQt5">
            <papertitle>CTPN CRNN ChineseOCR PyQt5</papertitle>
          </a>
          <br>
          <a>Qing Jiang</a>
          <br>
          <em>Github Repo, 13 stars</em>
          <br>
          <a href="https://github.com/Mountchicken/CTPN_CRNN_ChineseOCR_PyQt5">Github</a>
          <p>CTPN and CRNN based Chinese OCR, developed with PyQt5.
          </p>
        </td>
      </tr>
    </tbody>
  </table>

<table width="50%" align="center" border="0" cellpadding="20">
  <tbody>
    <tr>
      <td width="50%" valign="center"></td>
      <script type="text/javascript" id="clustrmaps"
        src="//clustrmaps.com/map_v2.js?d=zEuGs9CDAXseJAka9KDNEQckDn_266DHUDK8xaS2Qu0&cl=ffffff&w=a"></script>
      </td>
    </tr>
  </tbody>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody>
    <tr>
      <td style="padding:0px">
        <br>
        <p style="text-align:right;font-size:small;">
          <br>
          template adapted from <a href="https://github.com/yizhiwang96/yizhiwang96.github.io">Yizhi Wang</a>.
        </p>
      </td>
    </tr>
  </tbody>
</table>
</td>
</tr>
</table>



</body>
</html>
