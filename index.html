<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0030)https://pengsongyou.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Weifeng Lin</title>
  
  <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE">	
  <meta name="viewport" content="‚Äúwidth=800‚Äù">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">

  <style type="text/css">
    @import url(http://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700,700italic,900,900italic,300italic,300,100italic,100);
      /* Color scheme stolen from Sergey Karayev */
      a {
      /*color: #b60a1c;*/
      color: #1772d0;
      /*color: #bd0a36;*/
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09228;
      text-decoration:none;
      }
      body,td,th,tr,p,a {
      font-family: 'Roboto', sans-serif;
      font-size: 15px;
      font-weight: 300;
      }
      strong {
      font-family: 'Roboto', sans-serif;
      /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
      /*font-family: 'Avenir Next';*/
      font-size: 15px;
      font-weight: 400;
      }
      heading {
      /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
      font-family: 'Roboto', sans-serif;
      /*font-family: 'Avenir Next';*/
      /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
      font-size: 24px;
      font-weight: 400;
      }
      papertitle {
      /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
      font-family: 'Roboto', sans-serif;
      /*font-family: 'Avenir Next';*/
      /*src: url("./fonts/Roboto_Mono_for_Powerline.ttf");*/
      font-size: 15px;
      font-weight:500;
      }
      name {
      /*font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
      font-family: 'Roboto', sans-serif;
      /*font-family: 'Avenir Next';*/
      font-weight: 400;
      font-size: 32px;
      }
      .one
      {
      width: 160px;
      height: 140px;
      position: relative;
      }
      .two
      {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
      }
      .fade {
       transition: opacity .2s ease-in-out;
       -moz-transition: opacity .2s ease-in-out;
       -webkit-transition: opacity .2s ease-in-out;
      }
      span.highlight {
          background-color: #ffffd0;
      }
    </style>
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <!--<tr onmouseout="headshot_stop()" onmouseover="headshot_start()">-->
      <tbody><tr>
        <td width="70%" valign="middle">
          <p align="center">
            <name>Weifeng Lin (ÊûóÁÇú‰∏∞)</name>
          </p>

          <p>
            I am currently a PhD candidate at the <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory (MMLab)</a>, The Chinese University of Hong Kong, supervised by <a href="https://www.ee.cuhk.edu.hk/~hsli/">Prof. Hongsheng Li</a>. 
            I earned both my Bachelor's and Master's degrees from the <a href="https://www.scut.edu.cn/en//">South China University of Technology</a> in 2021 and 2024, respectively, where I had the privilege of being advised by <a href="http://www.dlvc-lab.net/lianwen/">Prof. Lianwen Jin</a> and enjoyed a memorable seven years.
          </p>
          <p>
            My research interests include Computer Vision (CV), Multimodal Large Language Models, and Generative Models. 
            I am deeply committed to contributing to open-source projects, as I firmly believe they are a cornerstone for the sustainable growth of the AI community.
          </p>
              
          <p align="center">
            <a href="wflin37@gmail.com">Email: wflin37@gmail.com</a> &nbsp/&nbsp
            <a href="https://scholar.google.com/citations?user=8iCZxIAAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
            <a href="https://github.com/Afeng-x">Github</a>
          </p>
          </td>

          <td width="33%">
            <a href="images/avater.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avater.jpg" class="hoverZoomLink"></a>
          </td>
        </tr>
        </tbody></table>
 
  <!-- Preprint -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Preprint</heading>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/pixwizard.jpg' width="166">
          </div>
        </td>
        <td valign="top" width="75%">
          <a
            href="https://arxiv.org/abs/2409.15278">
            <papertitle>PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions</papertitle>
          </a>
          <br>
          <strong>Weifeng Lin</strong>,
          <a>Xinyu Wei</a>,
          <a>Renrui Zhang</a>,
          <a>Le Zhuo</a>,
          <a>Shitian Zhao</a>,
          <a>Siyuan Huang</a>,
          <a>Junlin Xie</a>,
          <a>Yu Qiao</a>,
          <a>Peng Gao</a>,
          <a>Hongsheng Li</a>
          <br>
          <em>arxiv Preprint</em>, 2024
          <br>
          <a href="https://arxiv.org/abs/2409.15278 style="font-size: 16px;">[Paper] </a> |
          <a href="https://github.com/AFeng-x/PixWizard style="font-size: 16px;">[Code]  </a>
          <br>
          <p><strong>Keywords:</strong> Image Generation, Image-to-Image, Instruction-based Visual Assistant </p>
        </td>
      </tr>
    </tbody>
  </table>

  <!-- Publications -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Publications</heading>
        </td>
      </tr>
    </tbody>
  </table>
	
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/hst.jpg' width="166">
          </div>
        </td>
        <td valign="top" width="75%">
          <a
            href="https://arxiv.org/abs/2310.05393">
            <papertitle>Hierarchical Side-Tuning for Vision Transformers</papertitle>
          </a>
          <br>
          <strong>Weifeng Lin</strong>,
          <a>Ziheng Wu</a>,
          <a>Jiayu Chen</a>,
          <a>Wentao Yang</a>,
          <a>Mingxin Huang</a>,
          <a>Jun Huang</a>,
          <a>Lianwen Jin</a>,
          <br>
          <em>arxiv</em>, 2023
          <br>
          <a href="https://arxiv.org/abs/2310.05393">[paper] </a>
          <a href="https://github.com/AFeng-x/HST">[Code] </a>
          <br>
          <p>Parameter-efficient transfer learning for vision Transformers in various vision tasks (classification, detection, segmentation)</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/smt.jpg' width="166">
          </div>
        </td>
        <td valign="top" width="75%">
          <a
            href="https://arxiv.org/abs/2307.08579">
            <papertitle>Scale-Aware Modulation Meet Transformer</papertitle>
          </a>
          <br>
          <strong>Weifeng Lin</strong>,
          <a>Ziheng Wu</a>,
          <a>Jiayu Chen</a>,
          <a>Jun Huang</a>,
          <a>Lianwen Jin</a>,
          <br>
          <em>International Conference on Computer Vision <strong>(ICCV)</strong></em>, 2023
          <br>
          <a href="https://arxiv.org/abs/2307.08579">[paper] </a>
          <a href="https://github.com/AFeng-x/SMT">[Code] </a>
          <br>
          <p>Hybrid CNN-Transformer Network (Vision Transformer Backbone)</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
	    <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/rapid_diff.jpg' width="166" height="117">
          </div>
        </td>
        <td valign="top" width="75%">
					<a href="https://aclanthology.org/2023.acl-industry.28.pdf">
            <papertitle>Rapid Diffusion: Building Domain-Specific Text-to-Image Synthesizers with Fast Inference Speed</papertitle>
          </a>
          <br>
            <a>Bingyan Liu</a>,
            <strong>Weifeng Lin</strong>,
            <a>Zhongjie Duan</a>,
            <a>Chengyu Wang</a>,
            <a>Ziheng Wu</a>,
            <a>Zipeng Zhang</a>,
            <a>Kui Jia</a>,
            <a>Lianwen Jin</a>,
            <a>Cen Chen</a>
            <a>Jun Huang</a>
          <br>
          <em>Annual Meeting of the Association for Computational Linguistics <strong>(ACL-Industry)</strong></em>, 2023  
            <br>
							<a href="https://aclanthology.org/2023.acl-industry.28.pdf">[paper]</a> 
              <p>Rapid Diffusion is a novel framework for training and deploying superresolution, 
                text-to-image latent diffusion models with rich entity knowledge injected and optimized networks. </p>
        </td>
      </tr>
    </tbody>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
	    <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/mobile-NAS.jpg' width="166" height="117">
          </div>
        </td>
        <td valign="top" width="75%">
					<a href="">
            <papertitle>Building A Mobile Text Recognizer via Truncated SVD-based Knowledge Distillation-Guided NAS</papertitle>
          </a>
          <br>
            <strong>Weifeng Lin</strong>,
            <a>Canyu Xie</a>,
            <a>Dezhi Peng</a>,
            <a>Jiapeng Wang</a>,
            <a>Lianwen Jin</a>,
            <a>Wei Ding</a>,
            <a>Lianwen Jin</a>,
            <a>Cong Yao</a>
            <a>Mengchao He</a>
          <br>
          <em>British Machine Vision Conference <strong>(BMVC)</strong></em>, 2023  
            <br>
							<a href="https://papers.bmvc2023.org/0375.pdf">[paper]</a> 
              <a href="https://www.modelscope.cn/models/damo/cv_proxylessnas_ocr-detection-db-line-level_damo/summary">[Detection] </a>
              <a href="https://modelscope.cn/models/damo/cv_LightweightEdge_ocr-recognitoin-general_damo/summary">[Recognition] </a>
              <a href="https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/LiteWeightOCR">[Demo] </a>
              <p> We propose a mobile text recognizer that integrates Truncated Singular Value Decomposition (TSVD)-based Knowledge Distillation (KD) into the Neural Architecture Search (NAS) process </p>
        </td>
      </tr>
    </tbody>
  </table>

  <!-- Open source projects -->
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Internship</heading>
          <!-- <p>
            I am devoted to Open Source projects.
          </p> -->
        </td>
      </tr>
    </tbody>
  </table>
  
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
        <td width="25%">
          <div class="one">
            <img src='images/ali_cloud.jpg' width="160">
          </div>
        </td>
        <td valign="top" width="75%">
          <a href="https://www.alibabacloud.com/">
            <papertitle>Alibaba Cloud</papertitle>
          </a>
          <p>Research Intern, Machine Learning - Deep Learning Algorithms.</p>
        </td>
      </tr>
    </tbody>
  </table>


<table width="50%" align="center" border="0" cellpadding="20">
  <tbody>
    <tr>
      <td width="50%" valign="center"></td>
      <script type="text/javascript" id="clustrmaps"
        src="//clustrmaps.com/map_v2.js?d=zEuGs9CDAXseJAka9KDNEQckDn_266DHUDK8xaS2Qu0&cl=ffffff&w=a"></script>
      </td>
    </tr>
  </tbody>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td>
    <br>
    <p align="right">
      <font size="2">
      template adapted from <a href="https://jonbarron.info/"><font size="2">this awesome website</font></a>
      <!-- <br> -->
      <!-- Last updated: Mar 2023 -->
    </font>
    </p>
    </td>
  </tr>
  </table>



</body>
</html>
